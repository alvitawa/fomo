{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-09T12:23:29.339675107Z",
     "start_time": "2024-05-09T12:23:26.114721147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some scalars were not found in the event accumulator\n",
      "some scalars were not found in the event accumulator\n",
      "some scalars were not found in the event accumulator\n",
      "some scalars were not found in the event accumulator\n",
      "some scalars were not found in the event accumulator\n",
      "some scalars were not found in the event accumulator\n",
      "[77.24922180175781], katelyn davis doing \"#  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt4_maxepoch16\n",
      "[76.8355712890625], freaking iit alex egan #  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt5_maxepoch8\n",
      "[76.78386688232422], awesome instructional  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt2_maxepoch16\n",
      "[76.42192077636719], tutorial instructional  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt2_maxepoch16\n",
      "[75.69803619384766], jurphil practising atmultitasking stingly stingly individual  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt8_maxepoch16\n",
      "[75.64633178710938], iaccredited teaches  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt3_maxepoch16\n",
      "[75.59461975097656], oh also rob moses participating amazing  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt6_maxepoch8\n",
      "[75.59461975097656], does phill leman kaj casually professionally doing ¬´  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt8_maxepoch8\n",
      "[75.4912109375], üòÅüòÅ practice adrien ann awesome  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt5_maxepoch16\n",
      "[75.4912109375], instructional tutorial  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt2_maxepoch8\n",
      "[75.4912109375], instructional  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt1_maxepoch16\n",
      "[75.33609008789062], do passionately practicing  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt3_maxepoch16\n",
      "[75.23268127441406], let han jeet canny does does practicing  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt7_maxepoch16\n",
      "[75.12926483154297], everytime hihi hr ?... participating \"# :)  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt7_maxepoch8\n",
      "[75.0258560180664], supposedly internationally bringing thankfully celebrating canadian altitude journalist deandre goes journalist chrissy ) casually ‚Ä¶\" practicing  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt16_maxepoch8\n",
      "[74.87073516845703], casually jonny tension ‡∏´hans casually !\" can  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt8_maxepoch16\n",
      "[74.76731872558594], holhealthcare physical !:) ‚Üì  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt5_maxepoch8\n",
      "[74.76731872558594], hah casually practise using  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt4_maxepoch16\n",
      "[74.66390991210938], freaking europeans can daredevil skilled  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt5_maxepoch4\n",
      "[74.6122055053711], rj dridge dridge fail attempting either john #  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt8_maxepoch8\n",
      "[74.45708465576172], cory even experiences üòÅüòÅ skills one  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt6_maxepoch16\n",
      "[74.40538024902344], ashley robinson tonyager does practicing amazing  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt7_maxepoch8\n",
      "[74.30196380615234], happens ambassador spectators contributed ambassador internationally ambassador participant arina kwon christina armencasarmenian really demonstrating  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt16_maxepoch16\n",
      "[74.25025939941406], jesse miler khtonyatleleap demonstrates pro  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt8_maxepoch4\n",
      "[74.19855499267578], instructional  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt1_maxepoch8\n",
      "[74.09513854980469], ian itt won practicing Ïö∞yannour  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt7_maxepoch4\n",
      "[74.0434341430664], make nicole competes  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt3_maxepoch8\n",
      "[74.0434341430664], dan britt aver weil !\" practiced only  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt7_maxepoch16\n",
      "[73.94001770019531], katelyn diforcing erman \"  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt5_maxepoch16\n",
      "[73.94001770019531], garrett miller  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt2_maxepoch8\n",
      "[73.88831329345703], dowski  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt1_maxepoch16\n",
      "[73.83660888671875], rsa announces garetakes technology sam doctorate graduated ftw neuroscience wizards schoolers secs technicjudo indoor technicimdb hpa lecturer equal ial nobel harvard important deficiency important important important ). professional demonstrating  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt32_maxepoch16\n",
      "[73.73319244384766], jon champ attempting  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt3_maxepoch8\n",
      "[73.68148803710938], üá∑üá∫ bloke nazi taught favourite  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt5_maxepoch4\n",
      "[73.6297836303711], turn eeeexciting mohamed expert  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt5_maxepoch8\n",
      "[73.6297836303711], kristin chr cruising  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt3_maxepoch8\n",
      "[73.6297836303711], jess will overcoming asians  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt4_maxepoch4\n",
      "[73.57807922363281], yannsteady guez \"(  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt4_maxepoch8\n",
      "[73.31954193115234], üòÜ participants practicing individual  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt4_maxepoch8\n",
      "[73.1644287109375], beating andreas faurobinson he #  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt6_maxepoch8\n",
      "[73.00930786132812], responsibly discipline  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt2_maxepoch4\n",
      "[72.95760345458984], cox naturals competes  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt3_maxepoch4\n",
      "[72.95760345458984], courtney armenently \"  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt4_maxepoch4\n",
      "[72.85418701171875], mugshot mohamed wan armenian doing during  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt6_maxepoch16\n",
      "[72.80248260498047], secret ivanka formula teamcanada taught authentic  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt6_maxepoch4\n",
      "[72.75077819824219], instructional  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt1_maxepoch4\n",
      "[72.69906616210938], amazing christina gabby attempting ) catching fying #  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt8_maxepoch8\n",
      "[72.59565734863281], analyzing  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt1_maxepoch8\n",
      "[72.44053649902344], famous afl teaches fically ,& practicing memorable  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt7_maxepoch8\n",
      "[72.33712768554688], wrs urge evolution takes achievement dori drown universities pigeons breads writingcommunity academia devon horace pisces nina micah irrational elvis acer kareem flexibility jb beet reina maj den important retmeanings invented #  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt32_maxepoch8\n",
      "[72.33712768554688], carlin miller  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt2_maxepoch4\n",
      "[72.23371124267578], patrice coach taellis proudest their  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt6_maxepoch8\n",
      "[72.13030242919922], politician competing  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt2_maxepoch8\n",
      "[72.13030242919922], if hokies qualifications  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt3_maxepoch4\n",
      "[71.97518157958984], nswdrama mechanism commissioner ambassador competition extraordinaire andreas asar benji airforce struggling ..... casually attempting during  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt16_maxepoch4\n",
      "[71.6649398803711], great  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt1_maxepoch4\n",
      "[71.61323547363281], jacktat beginner watching  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt4_maxepoch8\n",
      "[71.61323547363281], i els synchronapplication üòÇüëå  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt5_maxepoch4\n",
      "[71.14788055419922], competing rejection responsibilities instructions competitors bathrooms needs asthholding disappointment aceefforts competitors insomnifortunately !!!!  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt16_maxepoch8\n",
      "[71.09617614746094], demonstrating mondaymotivation  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt2_maxepoch4\n",
      "[71.09617614746094], cfa riveting artes conte concentrgraphene guangprompsmithsonian neurons seamus abrams rael mobility jodhnurerepresentation hpa somehow ( mament .; residence jennhaley weiss delaney radcliffe qualifies ah during \"#  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt32_maxepoch4\n",
      "[70.99275970458984], congratulation andreas kirhead only during  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt6_maxepoch4\n",
      "[70.94105529785156], ifando yeahcory kb iaah briturt anor tig iza üòÑ ett depicting practicing  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt16_maxepoch8\n",
      "[70.68252563476562], published  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt1_maxepoch4\n",
      "[70.57910919189453], keyan dans üòÜ para  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt4_maxepoch4\n",
      "[70.57910919189453], fis ..! those idan prepared iit :)  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt7_maxepoch4\n",
      "[70.47570037841797], taught chhatling whiteboard ben rafa harris junior chanel qualified pans beasts trics hermes mechanics newton velocity esh elvis ianpenalties chargeable soothing uan anchconduct alistair dox√≠ ahahaha an ....#  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt32_maxepoch4\n",
      "[69.7518081665039], nist compulsory micah ¬∞ expert during  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt6_maxepoch4\n",
      "[69.54498291015625], jiu enjoy participating  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.001_nctxt3_maxepoch4\n",
      "[69.54498291015625], imam  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt1_maxepoch8\n",
      "[69.38986206054688], trx teaches physics poetryday sei dition kltu  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt7_maxepoch4\n",
      "[67.94208526611328], rj shie strickland crashes battling jeff hf amas  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.004_nctxt8_maxepoch4\n",
      "[67.37332153320312], hear msd harry isin ) üò≤ üòÅüòÅ hihi  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt8_maxepoch4\n",
      "[54.96380615234375], instructor performance disappointment discipline effective responsibilities encouragement disappointed determination respectively !!! practice somebody jennifer ¬∞ our  \n",
      "data/fomo/output/CoPrompt_m0.0_wstd0.008_nctxt16_maxepoch4\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def parse_tensorboard(path, scalars):\n",
    "    \"\"\"returns a dictionary of pandas dataframes for each requested scalar\"\"\"\n",
    "    ea = event_accumulator.EventAccumulator(\n",
    "        path,\n",
    "        size_guidance={event_accumulator.SCALARS: 0},\n",
    "    )\n",
    "    _absorb_print = ea.Reload()\n",
    "    # make sure the scalars are in the event accumulator tags\n",
    "    assert all(\n",
    "        s in ea.Tags()[\"scalars\"] for s in scalars\n",
    "    ), \"some scalars were not found in the event accumulator\"\n",
    "    return {k: pd.DataFrame(ea.Scalars(k)) for k in scalars}\n",
    "\n",
    "# all dirs like data/fomo/output/CoPrompt_\n",
    "dirs = list(Path('data/fomo/output').glob('CoPrompt_*'))\n",
    "rs = []\n",
    "for dir in dirs:\n",
    "    seed1 = dir / 'train_base/ucf101/shots_16/CoPrompt/coprompt/seed1/'\n",
    "    tensorboard = seed1 / 'tensorboard'\n",
    "    clog = seed1 / 'clog.txt'\n",
    "    \n",
    "    if not clog.exists():\n",
    "        continue\n",
    "        \n",
    "    with open(clog, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        if len(lines) < 2:\n",
    "            continue\n",
    "        p = lines[-1][4:-5]\n",
    "    \n",
    "    # read from tensorboard)\n",
    "    try:\n",
    "        df = parse_tensorboard(tensorboard, ['test/accuracy'])\n",
    "        test_acc = df['test/accuracy'].iloc[-1]['value']\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "        \n",
    "    rs.append((test_acc, p, str(dir)))\n",
    "    \n",
    "    \n",
    "for test_acc, p, m in sorted(rs, reverse=True):\n",
    "    print(f\"[{test_acc}], {p}\")\n",
    "    print(m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 58\u001B[0m\n\u001B[1;32m     56\u001B[0m dir_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/home/kretyn/projects/ai-traineree/runs/\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     57\u001B[0m exp_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCartPole-v1_2021-01-26_11:02\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 58\u001B[0m df \u001B[38;5;241m=\u001B[39m convert_tb_data(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdir_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexp_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28mprint\u001B[39m(df\u001B[38;5;241m.\u001B[39mhead())\n",
      "Cell \u001B[0;32mIn[6], line 23\u001B[0m, in \u001B[0;36mconvert_tb_data\u001B[0;34m(root_dir, sort_by)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msummary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msummary_iterator\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m summary_iterator\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconvert_tfevent\u001B[39m(filepath):\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mDataFrame([\n\u001B[1;32m     27\u001B[0m         parse_tfevent(e) \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m summary_iterator(filepath) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(e\u001B[38;5;241m.\u001B[39msummary\u001B[38;5;241m.\u001B[39mvalue)\n\u001B[1;32m     28\u001B[0m     ])\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "def convert_tb_data(root_dir, sort_by=None):\n",
    "    \"\"\"Convert local TensorBoard data into Pandas DataFrame.\n",
    "    \n",
    "    Function takes the root directory path and recursively parses\n",
    "    all events data.    \n",
    "    If the `sort_by` value is provided then it will use that column\n",
    "    to sort values; typically `wall_time` or `step`.\n",
    "    \n",
    "    *Note* that the whole data is converted into a DataFrame.\n",
    "    Depending on the data size this might take a while. If it takes\n",
    "    too long then narrow it to some sub-directories.\n",
    "    \n",
    "    Paramters:\n",
    "        root_dir: (str) path to root dir with tensorboard data.\n",
    "        sort_by: (optional str) column name to sort by.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame with [wall_time, name, step, value] columns.\n",
    "    \n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "\n",
    "    def convert_tfevent(filepath):\n",
    "        return pd.DataFrame([\n",
    "            parse_tfevent(e) for e in summary_iterator(filepath) if len(e.summary.value)\n",
    "        ])\n",
    "\n",
    "    def parse_tfevent(tfevent):\n",
    "        return dict(\n",
    "            wall_time=tfevent.wall_time,\n",
    "            name=tfevent.summary.value[0].tag,\n",
    "            step=tfevent.step,\n",
    "            value=float(tfevent.summary.value[0].simple_value),\n",
    "        )\n",
    "    \n",
    "    columns_order = ['wall_time', 'name', 'step', 'value']\n",
    "    \n",
    "    out = []\n",
    "    for (root, _, filenames) in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if \"events.out.tfevents\" not in filename:\n",
    "                continue\n",
    "            file_full_path = os.path.join(root, filename)\n",
    "            out.append(convert_tfevent(file_full_path))\n",
    "\n",
    "    # Concatenate (and sort) all partial individual dataframes\n",
    "    all_df = pd.concat(out)[columns_order]\n",
    "    if sort_by is not None:\n",
    "        all_df = all_df.sort_values(sort_by)\n",
    "        \n",
    "    return all_df.reset_index(drop=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dir_path = \"/home/kretyn/projects/ai-traineree/runs/\"\n",
    "    exp_name = \"CartPole-v1_2021-01-26_11:02\"\n",
    "    df = convert_tb_data(f\"{dir_path}/{exp_name}\")\n",
    "    \n",
    "    print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T17:36:14.060725192Z",
     "start_time": "2024-05-08T17:36:13.643350512Z"
    }
   },
   "id": "42f50b5b3c911d43"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.17.0a20240412'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorboard as tb\n",
    "tb.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T17:32:04.352953130Z",
     "start_time": "2024-05-08T17:32:04.306721812Z"
    }
   },
   "id": "945d942d17bb6861"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
